# Arquitectura del Sistema Multi-CÃ¡mara Inteligente para Hurones

## ğŸ¯ VisiÃ³n General

Este documento describe la arquitectura completa del **Ferret Multi-Camera Behavioral AI System**, un sistema de monitoreo inteligente basado en IA capaz de rastrear y analizar el comportamiento de hurones mediante mÃºltiples cÃ¡maras IP en tiempo real.

## ğŸ“ Arquitectura del Sistema

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CÃMARAS IP (RTSP)                       â”‚
â”‚  Camera 1    Camera 2    Camera 3    ...    Camera N        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAMERA MANAGER                            â”‚
â”‚  â€¢ ConexiÃ³n asÃ­ncrona a mÃºltiples streams                  â”‚
â”‚  â€¢ ReconexiÃ³n automÃ¡tica                                    â”‚
â”‚  â€¢ Buffer de frames por cÃ¡mara                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SYNC ENGINE                               â”‚
â”‚  â€¢ SincronizaciÃ³n temporal (timestamps)                     â”‚
â”‚  â€¢ AlineaciÃ³n de frames entre cÃ¡maras                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AI PIPELINE                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  DETECTOR   â”‚â†’ â”‚   TRACKER    â”‚â†’ â”‚  BEHAVIOR    â”‚      â”‚
â”‚  â”‚  (YOLOv8)   â”‚  â”‚ (DeepSORT+   â”‚  â”‚  CLASSIFIER  â”‚      â”‚
â”‚  â”‚             â”‚  â”‚   ReID)      â”‚  â”‚ (CNN+LSTM)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FUSION ENGINE                             â”‚
â”‚  â€¢ FusiÃ³n de detecciones multi-cÃ¡mara                      â”‚
â”‚  â€¢ EliminaciÃ³n de duplicados                               â”‚
â”‚  â€¢ CÃ¡lculo de posiciÃ³n 3D (opcional)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OUTPUTS & LOGGING                              â”‚
â”‚  â€¢ Event Logger  â€¢ Visualizer  â€¢ Dashboard API             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—‚ï¸ Estructura de Carpetas

```
ferret_monitoring/
â”‚
â”œâ”€â”€ main.py                      # Punto de entrada principal
â”œâ”€â”€ config.py                    # ConfiguraciÃ³n centralizada
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ README.md                    # DocumentaciÃ³n de usuario
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ arquitectura.md          # Este documento
â”‚   â”œâ”€â”€ api.md                   # DocumentaciÃ³n API
â”‚   â””â”€â”€ deployment.md            # GuÃ­a de despliegue
â”‚
â”œâ”€â”€ core/                        # MÃ³dulos centrales del sistema
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ camera_manager.py        # GestiÃ³n de streams RTSP
â”‚   â”œâ”€â”€ sync_engine.py           # SincronizaciÃ³n temporal
â”‚   â””â”€â”€ fusion_engine.py         # FusiÃ³n multi-cÃ¡mara
â”‚
â”œâ”€â”€ ai/                          # MÃ³dulos de inteligencia artificial
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ detector.py              # DetecciÃ³n de individuos (YOLOv8)
â”‚   â”œâ”€â”€ tracker.py               # Tracking + Re-ID multi-cÃ¡mara
â”‚   â”œâ”€â”€ behavior_model.py        # ClasificaciÃ³n de comportamientos
â”‚   â””â”€â”€ trainer.py               # Reentrenamiento incremental
â”‚
â”œâ”€â”€ data/                        # Datos del sistema
â”‚   â”œâ”€â”€ calibration/             # ParÃ¡metros de calibraciÃ³n de cÃ¡maras
â”‚   â”‚   â”œâ”€â”€ camera_1.json
â”‚   â”‚   â”œâ”€â”€ camera_2.json
â”‚   â”‚   â””â”€â”€ intrinsics.json
â”‚   â”œâ”€â”€ logs/                    # Logs de eventos y errores
â”‚   â”œâ”€â”€ models/                  # Modelos entrenados
â”‚   â”‚   â”œâ”€â”€ yolov8_ferret.pt
â”‚   â”‚   â”œâ”€â”€ reid_model.pth
â”‚   â”‚   â””â”€â”€ behavior_classifier.pth
â”‚   â””â”€â”€ training/                # Datos de entrenamiento
â”‚       â”œâ”€â”€ clips/
â”‚       â””â”€â”€ annotations/
â”‚
â””â”€â”€ utils/                       # Utilidades y helpers
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ visualizer.py            # VisualizaciÃ³n de resultados
    â”œâ”€â”€ logger.py                # Sistema de logging
    â””â”€â”€ synchronizer.py          # Herramientas de sincronizaciÃ³n
```

## ğŸ”§ Componentes Principales

### 1. Camera Manager (`core/camera_manager.py`)

**Responsabilidades:**
- ConexiÃ³n asÃ­ncrona a mÃºltiples streams RTSP
- GestiÃ³n de reconexiÃ³n automÃ¡tica ante fallos
- Buffer de frames por cÃ¡mara
- Control de FPS y resoluciÃ³n

**TecnologÃ­as:**
- OpenCV para captura de video
- Threading/asyncio para procesamiento paralelo
- Queue para buffering

**API Principal:**
```python
class CameraManager:
    def __init__(self, camera_urls: List[str])
    def start_all(self)
    def stop_all(self)
    def get_frames(self) -> Dict[int, np.ndarray]
    def is_camera_alive(self, camera_id: int) -> bool
```

### 2. Sync Engine (`core/sync_engine.py`)

**Responsabilidades:**
- SincronizaciÃ³n temporal de frames entre cÃ¡maras
- CompensaciÃ³n de latencias
- AlineaciÃ³n por timestamps
- Buffer temporal para sincronizaciÃ³n

**Algoritmo:**
1. Cada frame recibe timestamp de captura
2. Buffer mantiene ventana temporal (~500ms)
3. SelecciÃ³n de frames mÃ¡s cercanos temporalmente
4. InterpolaciÃ³n si es necesario

**API Principal:**
```python
class SyncEngine:
    def __init__(self, tolerance_ms: int = 100)
    def add_frame(self, camera_id: int, frame: np.ndarray, timestamp: float)
    def get_synced_frames(self) -> Dict[int, Tuple[np.ndarray, float]]
```

### 3. Fusion Engine (`core/fusion_engine.py`)

**Responsabilidades:**
- FusiÃ³n de detecciones de mÃºltiples cÃ¡maras
- EliminaciÃ³n de duplicados
- CÃ¡lculo de posiciÃ³n 3D (si hay calibraciÃ³n)
- Mantenimiento de identidades consistentes

**Algoritmos:**
- **Matching espacial:** ComparaciÃ³n de features ReID entre cÃ¡maras
- **Filtro de Kalman 3D:** PredicciÃ³n de posiciones
- **Hungarian Algorithm:** AsignaciÃ³n Ã³ptima de detecciones

**API Principal:**
```python
class FusionEngine:
    def __init__(self, calibration_path: str = None)
    def merge_detections(self, detections_per_camera: Dict) -> List[FusedObject]
    def eliminate_duplicates(self, objects: List) -> List[FusedObject]
    def calculate_3d_position(self, detections: List) -> np.ndarray
```

### 4. Detector (`ai/detector.py`)

**Responsabilidades:**
- DetecciÃ³n de hurones en frames individuales
- ExtracciÃ³n de bounding boxes y keypoints
- EstimaciÃ³n de pose (opcional)

**Modelo:**
- **YOLOv8** (ultralytics) fine-tuned para hurones
- Entrada: Frame RGB (640x640)
- Salida: Bounding boxes + confidence scores

**API Principal:**
```python
class BehaviorDetector:
    def __init__(self, model_path: str, confidence_threshold: float = 0.5)
    def detect(self, frame: np.ndarray) -> List[Detection]
    def batch_detect(self, frames: List[np.ndarray]) -> List[List[Detection]]
```

### 5. Tracker (`ai/tracker.py`)

**Responsabilidades:**
- Tracking de individuos dentro de una cÃ¡mara
- Re-identificaciÃ³n entre cÃ¡maras (ReID)
- Mantenimiento de IDs Ãºnicos globales

**TecnologÃ­as:**
- **DeepSORT** o **ByteTrack** para tracking local
- **OSNet/FastReID** para features de re-identificaciÃ³n
- Kalman Filter para predicciÃ³n de trayectorias

**API Principal:**
```python
class MultiCameraTracker:
    def __init__(self, reid_model_path: str)
    def update(self, detections_per_camera: Dict) -> List[TrackedObject]
    def get_global_id(self, local_id: int, camera_id: int) -> str
```

### 6. Behavior Model (`ai/behavior_model.py`)

**Responsabilidades:**
- ClasificaciÃ³n de comportamientos
- AnÃ¡lisis de secuencias temporales
- DetecciÃ³n de interacciones entre individuos

**Comportamientos Detectados:**
- Comer
- Dormir
- Jugar
- Desplazarse
- InteracciÃ³n social
- Comportamiento anÃ³malo

**Arquitectura del Modelo:**
- CNN para features espaciales (ResNet/EfficientNet)
- LSTM o Transformer para secuencias temporales
- Clasificador multi-clase

**API Principal:**
```python
class BehaviorClassifier:
    def __init__(self, model_path: str, sequence_length: int = 30)
    def classify(self, tracked_object: TrackedObject, frame_sequence: List) -> str
    def detect_interaction(self, objects: List[TrackedObject]) -> List[Interaction]
```

### 7. Trainer (`ai/trainer.py`)

**Responsabilidades:**
- Reentrenamiento incremental
- GestiÃ³n de nuevos datos anotados
- EvaluaciÃ³n de modelos
- ExportaciÃ³n de checkpoints

**Estrategia:**
- **Continual Learning** para evitar olvido catastrÃ³fico
- Replay buffer con muestras antiguas
- Fine-tuning periÃ³dico

**API Principal:**
```python
class IncrementalTrainer:
    def __init__(self, model: nn.Module, data_path: str)
    def add_training_data(self, clips: List, labels: List)
    def train_epoch(self) -> Dict[str, float]
    def evaluate(self) -> Dict[str, float]
    def save_checkpoint(self, path: str)
```

## ğŸ”„ Flujo de Datos

### Pipeline Completo

```
1. CAPTURA
   â””â”€ CameraManager captura frames de N cÃ¡maras

2. SINCRONIZACIÃ“N
   â””â”€ SyncEngine alinea frames temporalmente

3. DETECCIÃ“N
   â””â”€ Detector identifica hurones en cada frame
   â””â”€ Output: [camera_id, bbox, confidence, features]

4. TRACKING
   â””â”€ Tracker asigna IDs locales por cÃ¡mara
   â””â”€ ReID asigna ID global Ãºnico

5. FUSIÃ“N
   â””â”€ FusionEngine combina info de mÃºltiples cÃ¡maras
   â””â”€ Elimina duplicados
   â””â”€ Calcula posiciÃ³n 3D (opcional)

6. CLASIFICACIÃ“N DE COMPORTAMIENTO
   â””â”€ BehaviorClassifier analiza secuencias
   â””â”€ Output: [ferret_id, behavior, confidence, timestamp]

7. OUTPUT
   â””â”€ Logger guarda eventos
   â””â”€ Visualizer muestra resultados
   â””â”€ Dashboard API expone datos en tiempo real
```

## ğŸ›ï¸ ConfiguraciÃ³n

### config.py - ParÃ¡metros Principales

```python
# CÃ¡maras
CAMERA_URLS = [
    "rtsp://user:pass@192.168.1.10:554/stream1",
    "rtsp://user:pass@192.168.1.11:554/stream1"
]
CAMERA_FPS = 30
CAMERA_RESOLUTION = (1920, 1080)

# SincronizaciÃ³n
SYNC_TOLERANCE_MS = 100
SYNC_BUFFER_SIZE = 15

# DetecciÃ³n
DETECTION_MODEL = "models/yolov8_ferret.pt"
DETECTION_CONFIDENCE = 0.5
DETECTION_IOU = 0.45

# Tracking
REID_MODEL = "models/reid_model.pth"
MAX_AGE = 30  # frames sin detecciÃ³n antes de eliminar track
MIN_HITS = 3  # detecciones mÃ­nimas para confirmar track

# Comportamiento
BEHAVIOR_MODEL = "models/behavior_classifier.pth"
BEHAVIOR_SEQUENCE_LENGTH = 30  # frames para anÃ¡lisis

# Logging
LOG_LEVEL = "INFO"
LOG_FILE = "data/logs/system.log"
EVENT_LOG = "data/logs/events.log"
```

## ğŸ§ª Fases de Desarrollo

### âœ… Fase 1: ConexiÃ³n Multi-CÃ¡mara (EN PROGRESO)
**Objetivo:** Conectar 2+ cÃ¡maras y mostrar streams sincronizados

**Tareas:**
- [x] Implementar CameraManager bÃ¡sico
- [x] Implementar SyncEngine
- [x] Visualizar mosaico de cÃ¡maras
- [x] Descubrir URL RTSP correcta de cÃ¡mara real
- [x] Implementar soluciÃ³n FFmpeg para macOS
- [ ] Integrar FFmpegCamera en CameraManager
- [ ] Probar con stream en vivo

**Entregables:**
- Sistema capaz de mostrar mÃºltiples streams en tiempo real
- SincronizaciÃ³n bÃ¡sica por timestamps
- SoluciÃ³n compatible con macOS usando FFmpeg

**Notas de ImplementaciÃ³n (2025-11-08):**
- âœ… URL RTSP verificada: `rtsp://admin:Sb123456@192.168.0.20:554/Preview_01_main`
- âœ… CÃ¡mara: Reolink E1 Pro (E Series E330)
- âš ï¸  OpenCV tiene problemas con RTSP en macOS â†’ SoluciÃ³n: FFmpeg
- ğŸ“ Ver `README_CAMARA.md` y `SOLUCION_CAMARA.md` para detalles

### ğŸ“‹ Fase 2: DetecciÃ³n y Tracking Individual
**Objetivo:** Detectar y trackear hurones en cada cÃ¡mara independientemente

**Tareas:**
- [ ] Integrar YOLOv8 para detecciÃ³n
- [ ] Implementar DeepSORT para tracking local
- [ ] Visualizar bounding boxes con IDs locales

**Entregables:**
- DetecciÃ³n confiable de hurones
- Tracking consistente dentro de cada cÃ¡mara

### ğŸ“‹ Fase 3: Re-IdentificaciÃ³n Multi-CÃ¡mara
**Objetivo:** Mantener ID Ãºnico cuando hurÃ³n cambia de cÃ¡mara

**Tareas:**
- [ ] Entrenar/adaptar modelo ReID
- [ ] Implementar matching entre cÃ¡maras
- [ ] Sistema de IDs globales

**Entregables:**
- IDs Ãºnicos mantenidos entre cÃ¡maras
- Database de features por individuo

### ğŸ“‹ Fase 4: FusiÃ³n y EliminaciÃ³n de Duplicados
**Objetivo:** Combinar informaciÃ³n de mÃºltiples vistas

**Tareas:**
- [ ] Implementar algoritmo de fusiÃ³n
- [ ] EliminaciÃ³n de detecciones duplicadas
- [ ] CalibraciÃ³n de cÃ¡maras (opcional)
- [ ] CÃ¡lculo de posiciÃ³n 3D (opcional)

**Entregables:**
- Vista unificada sin duplicados
- Posiciones 3D aproximadas

### ğŸ“‹ Fase 5: Reconocimiento de Comportamientos
**Objetivo:** Clasificar actividades de hurones

**Tareas:**
- [ ] Recolectar dataset de comportamientos
- [ ] Entrenar modelo CNN+LSTM
- [ ] Implementar BehaviorClassifier
- [ ] Sistema de detecciÃ³n de interacciones

**Entregables:**
- ClasificaciÃ³n en tiempo real de 5+ comportamientos
- DetecciÃ³n de interacciones sociales

### ğŸ“‹ Fase 6: Dashboard en Tiempo Real
**Objetivo:** Interfaz web para monitoreo

**Tareas:**
- [ ] Backend API con FastAPI
- [ ] Frontend con React
- [ ] WebSocket para streaming en vivo
- [ ] VisualizaciÃ³n de estadÃ­sticas
- [ ] Sistema de alertas

**Entregables:**
- Dashboard web funcional
- API REST documentada
- Sistema de notificaciones

## ğŸ“Š MÃ©tricas y EvaluaciÃ³n

### Rendimiento del Sistema
- **FPS total:** â‰¥ 20 fps con 2 cÃ¡maras, â‰¥ 10 fps con 4 cÃ¡maras
- **Latencia de detecciÃ³n:** < 100ms por frame
- **Uso de GPU:** < 80% en inferencia continua

### PrecisiÃ³n de DetecciÃ³n
- **mAP (mean Average Precision):** > 0.85
- **Recall:** > 0.90 (para no perder individuos)
- **False Positives:** < 5% de detecciones

### Tracking
- **MOTA (Multiple Object Tracking Accuracy):** > 0.80
- **ID Switches:** < 10 por hora
- **Track Fragmentation:** < 15%

### Comportamiento
- **Accuracy de clasificaciÃ³n:** > 0.85 por clase
- **ConfusiÃ³n entre clases:** < 10%

## ğŸ” Consideraciones de Seguridad

- Credenciales RTSP almacenadas en variables de entorno
- EncriptaciÃ³n de comunicaciÃ³n con cÃ¡maras (si soportado)
- Logs sin informaciÃ³n sensible
- Control de acceso al dashboard

## ğŸš€ Despliegue

### Requisitos del Sistema
- **OS:** Linux (Ubuntu 20.04+) o macOS
- **Python:** 3.9+
- **GPU:** NVIDIA con CUDA 11.7+ (recomendado)
- **RAM:** 16GB mÃ­nimo, 32GB recomendado
- **Storage:** 100GB+ para logs y modelos

### InstalaciÃ³n
```bash
# Clonar repositorio
git clone <repo-url>
cd ferret_monitoring

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt

# Configurar cÃ¡maras
cp config.example.py config.py
# Editar config.py con URLs de cÃ¡maras

# Ejecutar
python main.py
```

## ğŸ“š Referencias TÃ©cnicas

### Papers
- **YOLOv8:** Ultralytics YOLOv8 Documentation
- **DeepSORT:** "Simple Online and Realtime Tracking with a Deep Association Metric"
- **ReID:** "Bag of Tricks and A Strong Baseline for Deep Person Re-identification"
- **Action Recognition:** "Temporal Segment Networks for Action Recognition in Videos"

### LibrerÃ­as Clave
- `opencv-python`: Procesamiento de video
- `torch`: Deep learning framework
- `ultralytics`: YOLOv8
- `deep-sort-realtime`: Tracking
- `torchreid`: Re-identificaciÃ³n
- `filterpy`: Kalman filters
- `fastapi`: API web
- `numpy`, `scipy`: Operaciones numÃ©ricas

## ğŸ”„ Mantenimiento y ActualizaciÃ³n

### Reentrenamiento PeriÃ³dico
- **Frecuencia:** Mensual o cuando accuracy < 0.80
- **Datos nuevos:** Clips capturados con etiquetas validadas
- **Estrategia:** Fine-tuning con learning rate bajo

### Monitoreo
- Logs de errores revisados semanalmente
- MÃ©tricas de rendimiento monitoreadas en tiempo real
- Alertas automÃ¡ticas si FPS < umbral

## ğŸ“ Soporte y Contacto

Para preguntas o reportar issues:
- DocumentaciÃ³n adicional: `/docs`
- Issues: GitHub Issues
- Email: [tu-email@ejemplo.com]

---

**Ãšltima actualizaciÃ³n:** {{ FECHA }}  
**VersiÃ³n del documento:** 1.0  
**Estado del proyecto:** Fase 1 - Desarrollo Inicial



